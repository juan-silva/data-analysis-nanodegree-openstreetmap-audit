{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Nanodegree - Project 3 Code\n",
    "**By: Juan Silva**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set\n",
    "\n",
    "**Area Chosen:**\n",
    "Ottawa, Ontario, Canada (Downtown)\n",
    "\n",
    "**Open Street Map Link:**\n",
    "http://www.openstreetmap.org/#map=13/45.4000/-75.6920\n",
    "\n",
    "**File:**\n",
    "ottawa.osm (83.3 MB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: MAKE SURE TO RUN THIS CELL FIRST BEFORE ANY CODE IN CELLS BELOW\n",
    "\n",
    "#define some global variables required for execution\n",
    "import xml.etree.cElementTree as ET\n",
    "import pprint\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import codecs\n",
    "import json\n",
    "#File to be processed\n",
    "filename = \"ottawa.osm\"\n",
    "#Helper regex vars to check tags keys condition\n",
    "lower = re.compile(r'^([a-z]|_)*$')\n",
    "lower_colon = re.compile(r'^([a-z]|_)*:([a-z]|_)*$')\n",
    "problemchars = re.compile(r'[=\\+/&<>;\\'\"\\?%#$@\\,\\. \\t\\r\\n]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Loop all the tags using an event based approach (Good for large files that can't fit in memory)\n",
    "tags = {}\n",
    "for event, elem in ET.iterparse(filename):\n",
    "    if elem.tag not in tags:\n",
    "        tags[elem.tag] = 1\n",
    "    else:\n",
    "        tags[elem.tag] = tags[elem.tag] + 1\n",
    "pprint.pprint(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Audit\n",
    "\n",
    "#### Key Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This function evaluates each tag element and classifies it in three buckets\n",
    "def key_type(element, keys):\n",
    "    if element.tag == \"tag\":\n",
    "        val = element.attrib[\"k\"]\n",
    "        if lower.match(val):\n",
    "            keys[\"lower\"] += 1\n",
    "        elif lower_colon.match(val):\n",
    "            keys[\"lower_colon\"] += 1\n",
    "        elif problemchars.match(val):\n",
    "            keys[\"problemchars\"] += 1\n",
    "        else:\n",
    "            keys[\"other\"] += 1\n",
    "    return keys\n",
    "\n",
    "#loop all elements checking tag's keys by type and counting them\n",
    "keys = {\"lower\": 0, \"lower_colon\": 0, \"problemchars\": 0, \"other\": 0}\n",
    "for _, element in ET.iterparse(filename):\n",
    "        keys = key_type(element, keys)\n",
    "\n",
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Street Naming and Postal Code Consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#New entries to handle the french version of street names\n",
    "expected_french = [\"Rue\", \"Boulevard\", \"Chemin\", \"Promenade\", \"Way\"]\n",
    "street_type_french_re = re.compile(r'^\\b\\S+\\.?', flags=re.IGNORECASE)\n",
    "\n",
    "#English version with added entries\n",
    "street_type_re = re.compile(r'\\b\\S+\\.?$', flags=re.IGNORECASE)\n",
    "expected = [\"Street\", \"Avenue\", \"Boulevard\", \"Drive\", \"Court\", \"Place\", \"Square\", \"Lane\", \"Road\", \n",
    "            \"Trail\", \"Parkway\", \"Commons\", \"Crescent\", \"Private\", \"Way\", \"Circle\", \"Driveway\", \n",
    "            \"South\", \"North\", \"East\", \"West\", \"Terrace\"]\n",
    "\n",
    "#Check if a particular street has an unexpected name and log it, handling the french scenario\n",
    "def audit_street_type(street_types, street_name):\n",
    "    m = street_type_re.search(street_name)\n",
    "    if m:\n",
    "        street_type = m.group()\n",
    "        if street_type not in expected:\n",
    "            #Let's check the french version before logging it\n",
    "            m_french = street_type_french_re.search(street_name)\n",
    "            street_type_french = m_french.group()\n",
    "            if street_type_french not in expected_french:\n",
    "                street_types[street_type].add(street_name)\n",
    "\n",
    "#Check if a particular element is a tag describing a street name\n",
    "def is_street_name(elem):\n",
    "    return (elem.attrib['k'] == \"addr:street\")\n",
    "\n",
    "#Loop all elements and check those that are nodes or ways (which can have addresses)\n",
    "street_types = defaultdict(set)\n",
    "for _, elem in ET.iterparse(filename):\n",
    "    if elem.tag == \"node\" or elem.tag == \"way\":\n",
    "        for tag in elem.iter(\"tag\"):\n",
    "            if is_street_name(tag):\n",
    "                audit_street_type(street_types, tag.attrib['v'])\n",
    "\n",
    "pprint.pprint(dict(street_types))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check postal codes\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient('localhost:27017')\n",
    "db = client.nanodegree\n",
    "\n",
    "pprint.pprint([doc for doc in db.ottawa.aggregate([\n",
    "        {\"$match\":{\"address.postcode\": {\"$not\": re.compile(\"^[A-Za-z]\\d[A-Za-z] ?\\d[A-Za-z]\\d$\")}}}, \n",
    "        {\"$group\":{\"_id\":\"$address.postcode\", \"count\":{\"$sum\":1}}}, \n",
    "        {\"$sort\":{\"count\":-1}}\n",
    "    ])])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Attributes of the new \"Created\" object for nodes \n",
    "CREATED = [ \"version\", \"changeset\", \"timestamp\", \"user\", \"uid\"]\n",
    "\n",
    "#The mapping dictionary for street abreviations and corresponding full words\n",
    "mapping = { \"Ave\": \"Avenue\",\n",
    "            \"Blvd.\": \"Boulevard\",\n",
    "            \"Blvd\": \"Boulevard\",\n",
    "            \"Boul.\": \"Boulevard\",\n",
    "            \"Dr.\": \"Drive\",\n",
    "            \"Rd\": \"Road\"\n",
    "            }\n",
    "#The mapping dictionary for postal codes that have incorrect entries\n",
    "postalMappings = {\n",
    "    'K2A OE8': 'K2A 0E8',\n",
    "    'K2P 0P4,': 'K2P 0P4',\n",
    "    'JOX 2W1': 'J0X 2W1',\n",
    "    'K1N 7E7\\u200e': 'K1N 7E7',\n",
    "    'K1N 9N8': 'K1N 9N8'\n",
    "}\n",
    "#The mapping dictionary to determine if parking fee enrtries require payment\n",
    "mappingPaidParking = {\n",
    "    'Daily fee': 'yes',\n",
    "    'no': 'no',\n",
    "    'interval': 'yes',\n",
    "    'yes': 'yes',\n",
    "    'customer parking': 'no',\n",
    "    'customers': 'no'\n",
    "}\n",
    "\n",
    "\n",
    "#Function used to fix street names as the JSON output is generated\n",
    "def update_name(name, mapping):\n",
    "    m = street_type_re.search(name)\n",
    "    if m and m.group() in mapping:\n",
    "        name = re.sub(r'\\b\\S+\\.?$', mapping[m.group()],name)\n",
    "    m_french = street_type_french_re.search(name)\n",
    "    if m_french and m_french.group() in mapping:\n",
    "        name = re.sub(r'^\\b\\S+\\.?', mapping[m_french.group()],name)\n",
    "    return name\n",
    "\n",
    "#Function used to fix postal codes as the JSON output is generated\n",
    "def update_code(code, mapping):\n",
    "    if code in mapping:\n",
    "        return mapping[code]\n",
    "    else:\n",
    "        return code\n",
    "\n",
    "#Function used to generate a new field that defines if payment is required for a parking entry\n",
    "def isPaidParking(val, mapping):\n",
    "    if val in mapping:\n",
    "        return mapping[val]\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "\n",
    "#Aux function to process a single xml element creating the JSON model\n",
    "def shape_element(element, mapping, postalMappings, mappingPaidParking):\n",
    "    node = {}\n",
    "    if element.tag == \"node\" or element.tag == \"way\" :\n",
    "        attrib = element.attrib\n",
    "        #General Fields\n",
    "        node[\"id\"] = attrib[\"id\"]\n",
    "        if \"visible\" in attrib:\n",
    "            node[\"visible\"] = attrib[\"visible\"]\n",
    "        #Created Fields\n",
    "        node[\"created\"] = {}\n",
    "        for item in CREATED:\n",
    "            node[\"created\"][item] = attrib[item]\n",
    "        #Type tags\n",
    "        node[\"type\"] = element.tag\n",
    "        if element.tag == \"node\":\n",
    "            node[\"pos\"] = [float(attrib[\"lat\"]), float(attrib[\"lon\"])]\n",
    "        if element.tag == \"way\":\n",
    "            node[\"node_refs\"] = []\n",
    "        #Process all tags, including address ones\n",
    "        node[\"address\"] = {}\n",
    "        for child in element:\n",
    "            if child.tag == \"tag\": \n",
    "                if child.attrib[\"k\"] == \"addr:housenumber\":\n",
    "                    node[\"address\"][\"housenumber\"] = child.attrib[\"v\"]\n",
    "                elif child.attrib[\"k\"] == \"addr:postcode\":\n",
    "                    node[\"address\"][\"postcode\"] = update_code(child.attrib[\"v\"], postalMappings)\n",
    "                elif child.attrib[\"k\"] == \"addr:street\":\n",
    "                    node[\"address\"][\"street\"] = update_name(child.attrib[\"v\"], mapping)\n",
    "                else:\n",
    "                    if child.attrib[\"k\"] == \"fee\":\n",
    "                        node[\"paid\"] = isPaidParking(child.attrib[\"v\"], mappingPaidParking)\n",
    "                    node[child.attrib[\"k\"]] = child.attrib[\"v\"]\n",
    "            if child.tag == \"nd\":\n",
    "                node[\"node_refs\"].append(child.attrib[\"ref\"])\n",
    "        if not node[\"address\"]:\n",
    "            del node[\"address\"]\n",
    "        return node\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "#Parse the input XML file and output the JSON file\n",
    "file_out = \"{0}.json\".format(filename)\n",
    "with codecs.open(file_out, \"w\") as fo:\n",
    "    for _, element in ET.iterparse(filename):\n",
    "        el = shape_element(element, mapping, postalMappings, mappingPaidParking)\n",
    "        if el:\n",
    "            fo.write(json.dumps(el) + \"\\n\")\n",
    "\n",
    "print \"Finished\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After this step, we have a json file in disk which is clean, formatted and ready to be imported. In order to do that we ran the following command:\n",
    "> mongoimport --host 127.0.0.1:27017 -d nanodegree -c ottawa  --file ottawa.osm.json\n",
    "\n",
    "Then we check the database to see if it conforms to what we would expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Connect to the DB\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient('localhost:27017')\n",
    "db = client.nanodegree\n",
    "\n",
    "print (\"===== This is the total of Nodes + Ways listed above ====\")\n",
    "print db.ottawa.count(); \n",
    "\n",
    "print \"==== This should match the general expected structure ====\"\n",
    "pprint.pprint(db.ottawa.find_one()) \n",
    "\n",
    "print \"==== This should match the expected structure for a way ====\"\n",
    "pprint.pprint(db.ottawa.find({\"type\":\"way\"})[0]) \n",
    "\n",
    "print \"==== The structure with one that has an address ====\"\n",
    "pprint.pprint(db.ottawa.find({\"address\": {\"$exists\": 1}})[0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have verified that the data was imported as expected. We are ready to do some analysis in MongoDB\n",
    "\n",
    "## Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Agregation, grouping by user and counting the elements (Output limmited to 100 for clarity in report)\n",
    "pprint.pprint([doc for doc in db.ottawa.aggregate([\n",
    "            {\"$group\": {\"_id\": \"$created.user\", \"Contributed Items\": {\"$sum\": 1}}},\n",
    "            {\"$project\": {\"_id\": 0, \"User\": \"$_id\", \"Contributed Items\": 1}},\n",
    "            {\"$sort\": {\"Contributed Items\": -1}},\n",
    "            {\"$limit\": 100}\n",
    "        ])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Agregation, Average contribution per user\n",
    "pprint.pprint([doc for doc in db.ottawa.aggregate([\n",
    "            {\"$group\": {\"_id\": \"$created.user\", \"ContributedItems\": {\"$sum\": 1}}},\n",
    "            {\"$group\": {\"_id\": \"User Average\", \"Contributed Items\": {\"$avg\": \"$ContributedItems\"}}},\n",
    "        ])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Aggregation grouping by amenity and counting entries\n",
    "pprint.pprint([doc for doc in db.ottawa.aggregate([\n",
    "            {\"$match\": {\"amenity\": {\"$exists\": 1}}},\n",
    "            {\"$group\": {\"_id\": \"$amenity\", \"Count\": {\"$sum\": 1}}},\n",
    "            {\"$sort\": {\"Count\": -1}}\n",
    "        ])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Map Reduce job to identify all the unique keys across all Parking documents\n",
    "map = \"function() { if(this.amenity == 'parking'){ for (var key in this) { emit(key, null); } } }\"\n",
    "reduce = \"function(key, stuff) { return null; }\"\n",
    "result = db.ottawa.map_reduce(map, reduce, \"myresults\")\n",
    "for doc in result.find():\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Breakdown by kind of Fee related to parking\n",
    "pprint.pprint([doc for doc in db.ottawa.aggregate([\n",
    "                {\"$match\": {\"amenity\": \"parking\"}},\n",
    "                {\"$group\": {\"_id\": \"$fee\", \"Count\": {\"$sum\": 1}}},\n",
    "            ])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Breakdown by kind of Access\n",
    "pprint.pprint([doc for doc in db.ottawa.aggregate([\n",
    "                {\"$match\": {\"amenity\": \"parking\"}},\n",
    "                {\"$group\": {\"_id\": \"$access\", \"Count\": {\"$sum\": 1}}},\n",
    "            ])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Breakdown by type of parking\n",
    "pprint.pprint([doc for doc in db.ottawa.aggregate([\n",
    "                {\"$match\": {\"amenity\": \"parking\"}},\n",
    "                {\"$group\": {\"_id\": \"$parking\", \"Count\": {\"$sum\": 1}}},\n",
    "            ])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Map Reduce job to identify all the unique keys across all Restaurant documents\n",
    "map = \"function() { if(this.amenity == 'restaurant'){ for (var key in this) { emit(key, null); } } }\"\n",
    "reduce = \"function(key, stuff) { return null; }\"\n",
    "result = db.ottawa.map_reduce(map, reduce, \"myresults\")\n",
    "for doc in result.find():\n",
    "    print doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Breakdown by type of Cuisine\n",
    "pprint.pprint([doc for doc in db.ottawa.aggregate([\n",
    "                {\"$match\": {\"amenity\": \"restaurant\"}},\n",
    "                {\"$group\": {\"_id\": \"$cuisine\", \"Count\": {\"$sum\": 1}}},\n",
    "                {\"$sort\": {\"Count\": -1}}\n",
    "            ])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Breakdown by Delivery availability\n",
    "pprint.pprint([doc for doc in db.ottawa.aggregate([\n",
    "                {\"$match\": {\"amenity\": \"restaurant\"}},\n",
    "                {\"$group\": {\"_id\": \"$delivery\", \"Count\": {\"$sum\": 1}}},\n",
    "                {\"$sort\": {\"Count\": -1}}\n",
    "            ])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Breakdown by Wheelchair Accessibility\n",
    "pprint.pprint([doc for doc in db.ottawa.aggregate([\n",
    "                {\"$match\": {\"amenity\": \"restaurant\"}},\n",
    "                {\"$group\": {\"_id\": \"$wheelchair\", \"Count\": {\"$sum\": 1}}},\n",
    "                {\"$sort\": {\"Count\": -1}}\n",
    "            ])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
